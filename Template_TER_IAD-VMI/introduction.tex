\chapter{Introduction}

Le jugement de la similarité d’images par l’humain s’appuie sur beaucoup de choses notamment les éléments de la scène et les aspects culturels. Pour nous les humains il nous est facile de juger de la similarité entre deux images, cependant la prédiction de la similarité perceptive humaine est un sujet de recherche difficile. Le processus visuel sous-jacent à cet aspect de la vision humaine fait appel à plusieurs niveaux différents d’analyse visuelle (formes, objets, texture, disposition, couleur…etc). Dans le cas de ce projet la similarité purement visuelle sera traitée sans prendre en compte la sémantique. Le transfert de style et la génération d’image par des architectures modernes de réseaux de neurones (VAE, ADalN, PIX2PIX, CycleGAN, BigGAN…etc). La première partie consiste à expérimenter la génération d’image avec pix2pix en utilisant les images de l’ensemble de données PASCAL avec et sans l’arrière-plan. Ensuite Nous allons expérimenter le BigGAN pré entrainé sur l’ensemble de données d’ImageNet.