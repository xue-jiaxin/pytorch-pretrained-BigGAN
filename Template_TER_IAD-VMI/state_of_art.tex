\chapter{État de l'art}

Un chapitre dédié à l'état de l'art doit décrire les concepts et méthodes déjà existant(e)s, en lien avec le travail que vous avez réalisé.

\section{La similarité visuelle en science cognitives}

Les objets peuvent être caractérisés selon un grand nombre de critères possibles, mais certaines caractéristiques sont plus utiles que d’autres pour donner un sens aux objets qui nous entourent. Dans [5] ils ont développé un modèle informatique de jugements de similarité pour les images du monde réel de 1854 objets.

\section{La similarité visuelle et l’apprentissage profond}

Les progrès récents des réseaux de neurones artificiels ont révolutionné la vision par ordinateur, mais ces systèmes de conception sont toujours surpassés par les humains, dans [1] ils ont comparé la perception des objets par le cerveau humain et par les machines (certain nombre de modèles informatiques, par exemple : Tal, Gabor, Hog, split-half…etc.).  Ils ont recueilli un vaste ensemble de données comprenant 26 675 mesures de dissimilarité perçue pour 2801 objets visuels chez 269 sujets humains.  Afin de mesurer la dissimilarité chez les humains, ils ont demandé de localiser une bille étrange dans un tableau contenant un objet parmi de multiples occurrences de l’autre. La réciproque du temps de recherche visuelle a été considérée comme une estimation de la dissimilarité perçue. Cette mesure se comporte comme une distance mathématique, elle présente une somme linéaire de plusieurs caractéristiques, elle explique la catégorisation visuelle rapide et est fortement corrélée avec les évaluations subjectives de la dissimilarité. Ils ont testé l’ensemble de mesures sur des modèles de calcul très répandu. Le meilleur modèle était un CNN mais il a été surpassé par la combinaison de tous les autres modèles. Leur conclusion était que tous les modèles informatiques montrent des modèles similaires d’écart par rapport à la perception humaine. 

Dans [2] ils voulaient savoir est-ce que l’apprentissage automatique peut expliquer les jugements humains de similarité de forme d’objets visuels. Alors ils ont analysé la performance des systèmes d’apprentissage métrique (distance ou similarité) y compris les DNN, sur un nouvel ensemble de données de jugement de similarité de forme d’objet visuel humain. Contrairement aux autres études ou ils demandaient aux participants de juger de la similarité lorsque les objets ou les scènes étaient rendus à partir d’un seul point de vue, eux ils ont utilisé un rendu à partir de plusieurs vues et ils ont demandé aux participants de juger de la similarité de forme de manière variable. Ils ont trouvé que les DNN ne parviennent pas à expliquer les données expérimentales, mais une métrique entraînée avec une représentation variable basée sur des parties produit un bon ajustement, ils ont aussi constaté que même si les DNN puissent apprendre à extraire la représentation basée sur les parties et devrait être capable d’apprendre à modéliser leurs données. Les réseaux entraînés avec une fonction “triplet loss” basée sur le jugement de similarité ne donne pas un bon résultat. Le mauvais résultat du DNN est causé par la non-convexité du problème d’optimisation dans l’espace des poids du réseau. Ils concluent que l’insensibilité du point de vue est un aspect critique de la perception de la forme visuelle humaine, et que les réseaux de neurones et d’autres méthodes d’apprentissage automatique devront apprendre des représentations insensibles au point de vue afin de rendre compte des jugements de similarité de forme d’objets visuels des humains.

La comparaison des représentations formées par les DNN avec celles utilisées par les humains est un défi, car les représentations psychologiques humaines ne peuvent pas être observées directement. Dans [3] ils ont évalué et proposé une amélioration de la correspondance entre les DNN et les représentations humaines. Leur approche consiste à résoudre le problème de comparaison en exploitant la relation étroite entre représentation et similarité, ce qui veut dire que pour chaque fonction de similarité sur un ensemble de paires de points de données correspond à une représentation implicite de ces points. Ce qui offre une base empirique pour la première évaluation de DNN en tant qu’une approximation des représentations psychologiques humaines.
  
Dans [4] ils ont démontré leur méthode sur le jeu de données CUB-200-2011 et Stanford Cars en appliquant leur architecture du DNN ProtoPNet. Leur expérience a montré que l’architecture de DNN qu’ils ont créé pouvait atteindre une précision comparable à avec ses analogues. Et lorsque plusieurs ProtoPNet sont combinés en un réseau plus vaste, celui-ci peut atteindre une précision équivalente à celle de certains des modèles profonds les plus performants. De plus, leur modèle offre un niveau d’interprétabilité qui est absent dans les modèles existants. 


\section{Les GANs et le transfert du style}