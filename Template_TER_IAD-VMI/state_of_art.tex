\chapter{État de l'art}


\section{Similarité visuelle en science cognitives}

Les objets peuvent être caractérisés selon un grand nombre de critères possibles, mais certaines caractéristiques sont plus utiles que d'autres pour donner un sens aux objets qui nous entourent. Dans \cite{hebart2020revealing} ils ont développé un modèle informatique de jugements de similarité pour les images du monde réel de 1854 objets. Le modèle a capturé la plupart de la variance explicable dans le jugement de la similarité et a produit 49 dimensions d'objets hautement reproductibles et significatives qui reflètent diverses propriétés conceptuelles et perceptuelles de ces objets. Ces dimensions prédisent le comportement de catégorisation externe et reflètent les jugements de similarité de ces catégories. D'après eux les humains peuvent évaluer avec précision les objets selon ces dimensions, ce qui conclue que les jugements de similarité humains peuvent être représentés par un ensemble de dimensions relativement réduit, interprétable et généralisable aux comportements externes. 

\section{Similarité visuelle}

Les progrès récents des réseaux de neurones artificiels ont révolutionné la vision par ordinateur, mais ces systèmes de conception sont toujours surpassés par les humains, dans \cite{pramod2016computational} ils ont comparé la perception des objets par le cerveau humain et par les machines (certain nombre de modèles informatiques, par exemple : Tal, Gabor, Hog, split-half…etc.).  Ils ont recueilli un vaste ensemble de données comprenant 26 675 mesures de dissimilarité perçue pour 2801 objets visuels chez 269 sujets humains.  Afin de mesurer la dissimilarité chez les humains, ils ont demandé de localiser une bille étrange dans un tableau contenant un objet parmi de multiples occurrences de l'autre. La réciproque du temps de recherche visuelle a été considérée comme une estimation de la dissimilarité perçue. Cette mesure se comporte comme une distance mathématique, elle présente une somme linéaire de plusieurs caractéristiques, elle explique la catégorisation visuelle rapide et elle est fortement corrélée avec les évaluations subjectives de la dissimilarité. Ils ont testé l'ensemble de mesures sur des modèles de calcul très répandu. Le meilleur modèle était un CNN mais il a été surpassé par la combinaison de tous les autres modèles. Leur conclusion était que tous les modèles informatiques montrent des modèles similaires d'écart par rapport à la perception humaine.

Dans \cite{german2020can} ils voulaient savoir est-ce que l'apprentissage automatique peut expliquer les jugements humains de similarité de forme d'objets visuels. Alors ils ont analysé la performance des systèmes d'apprentissage métrique (distance ou similarité) y compris les DNN, sur un nouvel ensemble de données de jugement de similarité de forme d'objet visuel humain. Contrairement aux autres études ou ils demandaient aux participants de juger de la similarité lorsque les objets ou les scènes étaient rendus à partir d'un seul point de vue, eux ils ont utilisé un rendu à partir de plusieurs points vues et ils ont demandé aux participants de juger de la similarité de forme de manière variable. Ils ont trouvé que les DNN ne parviennent pas à expliquer les données expérimentales, mais une méthode entraînée avec une représentation variable basée sur des parties produit un bon ajustement, ils ont aussi constaté que même si les DNN puissent apprendre à extraire la représentation basée sur les parties et devrait être capable d'apprendre à modéliser leurs données. Les réseaux entraînés avec une fonction “triplet loss” basée sur le jugement de similarité ne donne pas un bon résultat. Le mauvais résultat du DNN est causé par la non-convexité du problème d'optimisation dans l'espace des poids du réseau. Ils concluent que l'insensibilité du point de vue est un aspect critique de la perception de la forme visuelle humaine, et que les réseaux de neurones et d'autres méthodes d'apprentissage automatique devront apprendre des représentations insensibles au point de vue afin de rendre compte des jugements de similarité de forme d'objets visuels des humains.

La comparaison des représentations formées par les DNN avec celles utilisées par les humains est un défi, car les représentations psychologiques humaines ne peuvent pas être observées directement. Dans \cite{peterson2018evaluating} ils ont évalué et proposé une amélioration de la correspondance entre les DNN et les représentations humaines. Leur approche consiste à résoudre le problème de comparaison en exploitant la relation étroite entre représentation et similarité, ce qui veut dire que pour chaque fonction de similarité sur un ensemble de paires de points de données correspond à une représentation implicite de ces points. Ce qui offre une base empirique pour la première évaluation de DNN en tant qu'une approximation des représentations psychologiques humaines.

Dans \cite{chen2019this} ils ont démontré leur méthode sur le jeu de données CUB-200-2011 et Stanford Cars en appliquant leur architecture du DNN ProtoPNet. Leur expérience a montré que l'architecture de DNN qu'ils ont créé pouvait atteindre une précision comparable à avec ses analogues. Et lorsque plusieurs ProtoPNet sont combinés en un réseau plus vaste, celui-ci peut atteindre une précision équivalente à celle de certains des modèles profonds les plus performants. De plus, leur modèle offre un niveau d'interprétabilité qui est absent dans les modèles existants. 


\section{transfert du style et GAN}

Le transfert de style désigne une catégorie d'algorithme qui manipules les images numérique afin d'adopter l'apparence ou le style. La transformation de l'image se fait grâce aux réseaux neuronaux profonds. La géométrie et la texture sont des aspects fondamentaux du style visuel. Ils existent beaucoup de méthodes de transfert de style mais qui se concentrent que sur la texture et pas la géométrie. Dans \cite{kim2020deformable} ils ont proposé un transfert de style déformable DTS, une approche basée sur l'optimisation qui stylise à la fois la texture et la géométrie d'une image pour mieux correspondre à une autre image (similarité). Leur approche n'est pas limitée à un domaine particulier (comme le visage) et surtout elle n'a pas besoin d'un apprentissage de paires style/contenu. Elle est basée sur des points clés sélectionnés dans l'image source et l'image but ensuite ils vont rapprocher ces points clés afin de changer la forme et enfin ils changent la texture.

En 2014, Ian Goodfellow et al. \cite{goodfellow2014generative} ont publié un article intitulé \og{}Adversarial Generative Networks\fg{}, qui propose une nouvelle méthode de training le modèle génératif. L'article indique que le GAN peut générer de nouveaux images des numériques manuscrites de MNIST, des CIFAR-10, et de TFD après un entrainement comme jeu. Ces dernière années, GAN a beaucoup d'application dans le domaine de génération d'œuvres d'art, et de transfert du style.





