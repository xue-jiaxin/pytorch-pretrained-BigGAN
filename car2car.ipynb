{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511",
   "display_name": "Python 3.8.5 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/Users/xuejiaxin/Dropbox/My Mac (Jiaxin的MacBook Pro)/Documents/GitHub/latent/pytorch-pretrained-BigGAN/other_class/same_class\n"
     ]
    }
   ],
   "source": [
    "cd \"./same_class/car2car/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:pytorch_pretrained_biggan.model:loading model biggan-deep-128 from cache at /Users/xuejiaxin/.pytorch_pretrained_biggan/6371c3777477e4e75187da1b9b526561aac3134f38c7299a3438009ae560e20d.3434ebdfa74a8c17e0e56061cfd905fa163c92f110e88df77b47da6ce9910b48\n",
      "INFO:pytorch_pretrained_biggan.model:Model config {\n",
      "  \"attention_layer_position\": 8,\n",
      "  \"channel_width\": 128,\n",
      "  \"class_embed_dim\": 128,\n",
      "  \"eps\": 0.0001,\n",
      "  \"layers\": [\n",
      "    [\n",
      "      false,\n",
      "      16,\n",
      "      16\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      16,\n",
      "      16\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      16,\n",
      "      16\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      16,\n",
      "      8\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      8,\n",
      "      8\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      8,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      4,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      4,\n",
      "      2\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      2,\n",
      "      2\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      2,\n",
      "      1\n",
      "    ]\n",
      "  ],\n",
      "  \"n_stats\": 51,\n",
      "  \"num_classes\": 1000,\n",
      "  \"output_dim\": 128,\n",
      "  \"z_dim\": 128\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_biggan.utils:Saving image to car_target_0.png\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# target image\n",
    "import torch\n",
    "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
    "                                       save_as_images, display_in_terminal, one_hot_from_int)\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "model = BigGAN.from_pretrained('biggan-deep-128')\n",
    "\n",
    "truncation = 0.5\n",
    "class_vector = one_hot_from_int(581)\n",
    "#class_vector = one_hot_from_names([\"car\"], batch_size=1)\n",
    "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=1, seed = 5)\n",
    "\n",
    "noise_vector = torch.from_numpy(noise_vector)\n",
    "class_vector = torch.from_numpy(class_vector)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "save_as_images(output, \"car_target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_0_0.png\n",
      "  1%|          | 2/200 [00:10<17:23,  5.27s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_2_0.png\n",
      "  2%|▏         | 4/200 [00:19<16:13,  4.97s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_4_0.png\n",
      "  3%|▎         | 6/200 [00:29<16:02,  4.96s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_6_0.png\n",
      "  4%|▍         | 8/200 [00:38<15:40,  4.90s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_8_0.png\n",
      "  5%|▌         | 10/200 [00:47<14:56,  4.72s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_10_0.png\n",
      "  6%|▌         | 12/200 [00:56<14:13,  4.54s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_12_0.png\n",
      "  7%|▋         | 14/200 [01:05<14:09,  4.57s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_14_0.png\n",
      "  8%|▊         | 16/200 [01:14<13:43,  4.48s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_16_0.png\n",
      "  9%|▉         | 18/200 [01:23<13:15,  4.37s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_18_0.png\n",
      " 10%|█         | 20/200 [01:33<14:04,  4.69s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_20_0.png\n",
      " 11%|█         | 22/200 [01:43<14:24,  4.86s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_22_0.png\n",
      " 12%|█▏        | 24/200 [01:53<14:20,  4.89s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_24_0.png\n",
      " 13%|█▎        | 26/200 [02:08<19:16,  6.65s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_26_0.png\n",
      " 14%|█▍        | 28/200 [02:23<19:45,  6.89s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_28_0.png\n",
      " 15%|█▌        | 30/200 [02:39<20:25,  7.21s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_30_0.png\n",
      " 16%|█▌        | 32/200 [03:06<31:06, 11.11s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_32_0.png\n",
      " 17%|█▋        | 34/200 [03:48<45:06, 16.30s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_34_0.png\n",
      " 18%|█▊        | 36/200 [04:15<39:04, 14.29s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_36_0.png\n",
      " 19%|█▉        | 38/200 [04:24<25:50,  9.57s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_38_0.png\n",
      " 20%|██        | 40/200 [04:35<19:57,  7.48s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_40_0.png\n",
      " 21%|██        | 42/200 [04:46<16:57,  6.44s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_42_0.png\n",
      " 22%|██▏       | 44/200 [04:56<15:14,  5.86s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_44_0.png\n",
      " 23%|██▎       | 46/200 [05:07<14:25,  5.62s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_46_0.png\n",
      " 24%|██▍       | 48/200 [05:18<14:03,  5.55s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_48_0.png\n",
      " 25%|██▌       | 50/200 [05:28<13:31,  5.41s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_50_0.png\n",
      " 26%|██▌       | 52/200 [05:38<12:58,  5.26s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_52_0.png\n",
      " 27%|██▋       | 54/200 [05:48<12:35,  5.17s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_54_0.png\n",
      " 28%|██▊       | 56/200 [05:58<12:22,  5.16s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_56_0.png\n",
      " 29%|██▉       | 58/200 [06:08<12:02,  5.09s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_58_0.png\n",
      " 30%|███       | 60/200 [06:17<11:40,  5.00s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_60_0.png\n",
      " 31%|███       | 62/200 [06:28<11:48,  5.13s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_62_0.png\n",
      " 32%|███▏      | 64/200 [06:37<10:53,  4.80s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_64_0.png\n",
      " 33%|███▎      | 66/200 [06:47<10:57,  4.90s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_66_0.png\n",
      " 34%|███▍      | 68/200 [06:57<11:05,  5.04s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_68_0.png\n",
      " 35%|███▌      | 70/200 [07:06<10:17,  4.75s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_70_0.png\n",
      " 36%|███▌      | 72/200 [07:15<10:16,  4.81s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_72_0.png\n",
      " 37%|███▋      | 74/200 [07:25<10:05,  4.80s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_74_0.png\n",
      " 38%|███▊      | 76/200 [07:35<10:22,  5.02s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_76_0.png\n",
      " 39%|███▉      | 78/200 [07:45<10:11,  5.02s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_78_0.png\n",
      " 40%|████      | 80/200 [07:55<09:53,  4.95s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_80_0.png\n",
      " 41%|████      | 82/200 [08:05<10:07,  5.15s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_82_0.png\n",
      " 42%|████▏     | 84/200 [08:15<09:36,  4.97s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_84_0.png\n",
      " 43%|████▎     | 86/200 [08:24<09:16,  4.88s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_86_0.png\n",
      " 44%|████▍     | 88/200 [08:33<09:03,  4.86s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_88_0.png\n",
      " 45%|████▌     | 90/200 [08:43<09:06,  4.97s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_90_0.png\n",
      " 46%|████▌     | 92/200 [08:55<09:40,  5.38s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_92_0.png\n",
      " 47%|████▋     | 94/200 [09:06<10:01,  5.67s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_94_0.png\n",
      " 48%|████▊     | 96/200 [09:18<09:55,  5.73s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_96_0.png\n",
      " 49%|████▉     | 98/200 [09:29<09:47,  5.76s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_98_0.png\n",
      " 50%|█████     | 100/200 [09:39<09:03,  5.43s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_100_0.png\n",
      " 51%|█████     | 102/200 [09:51<09:06,  5.57s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_102_0.png\n",
      " 52%|█████▏    | 104/200 [10:02<08:58,  5.61s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_104_0.png\n",
      " 53%|█████▎    | 106/200 [10:13<08:47,  5.62s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_106_0.png\n",
      " 54%|█████▍    | 108/200 [10:23<08:22,  5.47s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_108_0.png\n",
      " 55%|█████▌    | 110/200 [10:34<08:08,  5.43s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_110_0.png\n",
      " 56%|█████▌    | 112/200 [10:43<07:36,  5.19s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_112_0.png\n",
      " 57%|█████▋    | 114/200 [10:54<07:33,  5.27s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_114_0.png\n",
      " 58%|█████▊    | 116/200 [11:08<08:23,  5.99s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_116_0.png\n",
      " 59%|█████▉    | 118/200 [11:23<09:25,  6.90s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_118_0.png\n",
      " 60%|██████    | 120/200 [11:30<06:37,  4.97s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_120_0.png\n",
      " 61%|██████    | 122/200 [11:43<07:57,  6.12s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_122_0.png\n",
      " 62%|██████▏   | 124/200 [11:54<07:13,  5.70s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_124_0.png\n",
      " 63%|██████▎   | 126/200 [12:02<05:49,  4.72s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_126_0.png\n",
      " 64%|██████▍   | 128/200 [12:10<05:25,  4.52s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_128_0.png\n",
      " 65%|██████▌   | 130/200 [12:18<04:59,  4.28s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_130_0.png\n",
      " 66%|██████▌   | 132/200 [12:27<05:00,  4.42s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_132_0.png\n",
      " 67%|██████▋   | 134/200 [12:36<04:45,  4.33s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_134_0.png\n",
      " 68%|██████▊   | 136/200 [12:46<04:52,  4.57s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_136_0.png\n",
      " 69%|██████▉   | 138/200 [12:54<04:36,  4.46s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_138_0.png\n",
      " 70%|███████   | 140/200 [13:03<04:17,  4.29s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_140_0.png\n",
      " 71%|███████   | 142/200 [13:11<04:06,  4.25s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_142_0.png\n",
      " 72%|███████▏  | 144/200 [13:19<03:55,  4.20s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_144_0.png\n",
      " 73%|███████▎  | 146/200 [13:28<03:52,  4.31s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_146_0.png\n",
      " 74%|███████▍  | 148/200 [13:37<03:50,  4.44s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_148_0.png\n",
      " 75%|███████▌  | 150/200 [13:45<03:23,  4.08s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_150_0.png\n",
      " 76%|███████▌  | 152/200 [13:54<03:22,  4.22s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_152_0.png\n",
      " 77%|███████▋  | 154/200 [14:02<03:05,  4.04s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_154_0.png\n",
      " 78%|███████▊  | 156/200 [14:10<02:54,  3.97s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_156_0.png\n",
      " 79%|███████▉  | 158/200 [14:18<02:53,  4.13s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_158_0.png\n",
      " 80%|████████  | 160/200 [14:26<02:40,  4.01s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_160_0.png\n",
      " 81%|████████  | 162/200 [14:34<02:34,  4.06s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_162_0.png\n",
      " 82%|████████▏ | 164/200 [14:42<02:24,  4.02s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_164_0.png\n",
      " 83%|████████▎ | 166/200 [14:50<02:16,  4.02s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_166_0.png\n",
      " 84%|████████▍ | 168/200 [14:59<02:12,  4.14s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_168_0.png\n",
      " 85%|████████▌ | 170/200 [15:07<02:03,  4.13s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_170_0.png\n",
      " 86%|████████▌ | 172/200 [15:16<01:57,  4.21s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_172_0.png\n",
      " 87%|████████▋ | 174/200 [15:24<01:50,  4.25s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_174_0.png\n",
      " 88%|████████▊ | 176/200 [15:33<01:40,  4.17s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_176_0.png\n",
      " 89%|████████▉ | 178/200 [15:41<01:34,  4.29s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_178_0.png\n",
      " 90%|█████████ | 180/200 [15:49<01:22,  4.13s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_180_0.png\n",
      " 91%|█████████ | 182/200 [15:57<01:12,  4.03s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_182_0.png\n",
      " 92%|█████████▏| 184/200 [16:06<01:08,  4.30s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_184_0.png\n",
      " 93%|█████████▎| 186/200 [16:15<01:00,  4.33s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_186_0.png\n",
      " 94%|█████████▍| 188/200 [16:25<00:58,  4.85s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_188_0.png\n",
      " 95%|█████████▌| 190/200 [16:34<00:46,  4.65s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_190_0.png\n",
      " 96%|█████████▌| 192/200 [16:42<00:35,  4.38s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_192_0.png\n",
      " 97%|█████████▋| 194/200 [16:51<00:25,  4.30s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_194_0.png\n",
      " 98%|█████████▊| 196/200 [17:00<00:17,  4.48s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_196_0.png\n",
      " 99%|█████████▉| 198/200 [17:10<00:09,  4.68s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to car2car_198_0.png\n",
      "100%|██████████| 200/200 [17:19<00:00,  5.20s/it]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import squeezenet1_0\n",
    "from tqdm import trange\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.eval().to(DEVICE)\n",
    "\n",
    "\n",
    "semantic_model = squeezenet1_0(pretrained=True).to(DEVICE)\n",
    "semantic_model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Flatten()\n",
    "    )\n",
    "semantic_model = semantic_model.eval()\n",
    "\n",
    "trunction = 0.5\n",
    "\n",
    "class_vector = one_hot_from_int(c)\n",
    "#class_vector = one_hot_from_names(['car'], batch_size=1)\n",
    "class_vector = torch.from_numpy(class_vector)\n",
    "\n",
    "noise = truncated_noise_sample(truncation=truncation, batch_size=1, seed=99)\n",
    "noise = torch.nn.Parameter(torch.tensor(noise, requires_grad=True).float().to(DEVICE))\n",
    "noise_optim = torch.optim.Adam([noise], lr=0.05)\n",
    "\n",
    "\n",
    "\n",
    "L = []\n",
    "L_pixel = []\n",
    "L_semantic = []\n",
    "\n",
    "for iteration in trange(0, 200):\n",
    "    noise_optim.zero_grad()\n",
    "\n",
    "    y_hat = model(noise, class_vector, truncation)\n",
    "\n",
    "    semantic_loss = ((semantic_model(y_hat) - semantic_model(output)) ** 2).mean() ** .5 #-cos_sim(semantic_model(y_hat), semantic_model(output))\n",
    "    L_semantic.append(semantic_loss.item())\n",
    "\n",
    "    pixel_loss = abs(y_hat - output).mean()\n",
    "    L_pixel.append(pixel_loss.item())\n",
    "\n",
    "    loss = semantic_loss + 30 * pixel_loss\n",
    "    L.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    noise_optim.step()\n",
    "\n",
    "    if iteration % 2 == 0:\n",
    "        save_as_images(y_hat, f\"car2car_{iteration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'L' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9971f4001962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mL_pixel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_semantic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'L' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(L)\n",
    "plt.plot([x*30 for x in L_pixel], 'r')\n",
    "plt.plot(L_semantic, 'b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}