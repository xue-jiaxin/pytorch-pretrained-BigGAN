{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511",
   "display_name": "Python 3.8.5 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/Users/xuejiaxin/Dropbox/My Mac (Jiaxinçš„MacBook Pro)/Documents/GitHub/latent/pytorch-pretrained-BigGAN/diff_class_1\n"
     ]
    }
   ],
   "source": [
    "cd \"./diff_class_1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:pytorch_pretrained_biggan.model:loading model biggan-deep-128 from cache at /Users/xuejiaxin/.pytorch_pretrained_biggan/6371c3777477e4e75187da1b9b526561aac3134f38c7299a3438009ae560e20d.3434ebdfa74a8c17e0e56061cfd905fa163c92f110e88df77b47da6ce9910b48\n",
      "INFO:pytorch_pretrained_biggan.model:Model config {\n",
      "  \"attention_layer_position\": 8,\n",
      "  \"channel_width\": 128,\n",
      "  \"class_embed_dim\": 128,\n",
      "  \"eps\": 0.0001,\n",
      "  \"layers\": [\n",
      "    [\n",
      "      false,\n",
      "      16,\n",
      "      16\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      16,\n",
      "      16\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      16,\n",
      "      16\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      16,\n",
      "      8\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      8,\n",
      "      8\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      8,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      4,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      4,\n",
      "      2\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      2,\n",
      "      2\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      2,\n",
      "      1\n",
      "    ]\n",
      "  ],\n",
      "  \"n_stats\": 51,\n",
      "  \"num_classes\": 1000,\n",
      "  \"output_dim\": 128,\n",
      "  \"z_dim\": 128\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_biggan.utils:Saving image to dog_target_0.png\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# target image\n",
    "import torch\n",
    "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
    "                                       save_as_images, display_in_terminal, one_hot_from_int)\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "model = BigGAN.from_pretrained('biggan-deep-128')\n",
    "\n",
    "truncation = 0.5\n",
    "class_vector = one_hot_from_names([\"dog\"], batch_size=1)\n",
    "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=1, seed = 10)\n",
    "\n",
    "noise_vector = torch.from_numpy(noise_vector)\n",
    "class_vector = torch.from_numpy(class_vector)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "save_as_images(output, \"dog_target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import squeezenet1_0\n",
    "from tqdm import trange\n",
    "from torch import nn\n",
    "\n",
    "DEVICE = 'cpu'\n",
    "model = model.eval().to(DEVICE)\n",
    "\n",
    "\n",
    "semantic_model = squeezenet1_0(pretrained=True).to(DEVICE)\n",
    "semantic_model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Flatten()\n",
    "    )\n",
    "semantic_model = semantic_model.eval()\n",
    "\n",
    "soft_max = nn.Softmax(dim = 1)\n",
    "cos_sim = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "\n",
    "truncation = 0.5\n",
    "noise = truncated_noise_sample(truncation=truncation, batch_size=1, seed=10)\n",
    "noise = torch.nn.Parameter(torch.tensor(noise, requires_grad=True).float().to(DEVICE))\n",
    "\n",
    "class_vector = one_hot_from_names(['tabby cat'], batch_size=1)\n",
    "class_vector = torch.nn.Parameter(torch.tensor(class_vector, requires_grad=True).float().to(DEVICE))\n",
    "\n",
    "optim = torch.optim.Adam([noise, class_vector], lr=0.05)\n",
    "\n",
    "save_as_images(model(noise, class_vector, truncation), f\"start\")\n",
    "\n",
    "L = []\n",
    "L_pixel = []\n",
    "L_semantic = []\n",
    "\n",
    "for iteration in trange(0, 301):\n",
    "    optim.zero_grad()\n",
    "\n",
    "    output_1 = torch.nn.functional.gumbel_softmax(class_vector, tau=1, hard=True)\n",
    "    #output_1 = soft_max(class_vector)\n",
    "\n",
    "    y_hat = model(noise, output_1, truncation)\n",
    "\n",
    "    semantic_loss = -((semantic_model(y_hat) - semantic_model(output)) ** 2).mean() ** .5 \n",
    "    #semantic_loss = -cos_sim(semantic_model(y_hat), semantic_model(output))\n",
    "    L_semantic.append(semantic_loss.item())\n",
    "\n",
    "    pixel_loss = abs(y_hat - output).mean()\n",
    "    L_pixel.append(pixel_loss.item())\n",
    "\n",
    "    loss = semantic_loss + 25 * pixel_loss\n",
    "    L.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "\n",
    "    if iteration % 1 == 0:\n",
    "        print(output_1.argmax())\n",
    "        save_as_images(y_hat, f\"cat2dog_{iteration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}