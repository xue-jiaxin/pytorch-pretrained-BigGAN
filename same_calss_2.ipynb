{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511",
   "display_name": "Python 3.8.5 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Errno 2] No such file or directory: './other_class/'\n/Users/xuejiaxin/Dropbox/My Mac (Jiaxin的MacBook Pro)/Documents/GitHub/latent/pytorch-pretrained-BigGAN/other_class/butterfly2butterfly\n"
     ]
    }
   ],
   "source": [
    "cd \"./other_class/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Errno 2] No such file or directory: './butterfly2butterfly'\n/Users/xuejiaxin/Dropbox/My Mac (Jiaxin的MacBook Pro)/Documents/GitHub/latent/pytorch-pretrained-BigGAN/other_class/butterfly2butterfly\n"
     ]
    }
   ],
   "source": [
    "cd \"./butterfly2butterfly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "INFO:pytorch_pretrained_biggan.model:loading model biggan-deep-128 from cache at /Users/xuejiaxin/.pytorch_pretrained_biggan/6371c3777477e4e75187da1b9b526561aac3134f38c7299a3438009ae560e20d.3434ebdfa74a8c17e0e56061cfd905fa163c92f110e88df77b47da6ce9910b48\n",
      "INFO:pytorch_pretrained_biggan.model:Model config {\n",
      "  \"attention_layer_position\": 8,\n",
      "  \"channel_width\": 128,\n",
      "  \"class_embed_dim\": 128,\n",
      "  \"eps\": 0.0001,\n",
      "  \"layers\": [\n",
      "    [\n",
      "      false,\n",
      "      16,\n",
      "      16\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      16,\n",
      "      16\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      16,\n",
      "      16\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      16,\n",
      "      8\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      8,\n",
      "      8\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      8,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      4,\n",
      "      4\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      4,\n",
      "      2\n",
      "    ],\n",
      "    [\n",
      "      false,\n",
      "      2,\n",
      "      2\n",
      "    ],\n",
      "    [\n",
      "      true,\n",
      "      2,\n",
      "      1\n",
      "    ]\n",
      "  ],\n",
      "  \"n_stats\": 51,\n",
      "  \"num_classes\": 1000,\n",
      "  \"output_dim\": 128,\n",
      "  \"z_dim\": 128\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_target_0.png\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# target image\n",
    "import torch\n",
    "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_names, truncated_noise_sample,\n",
    "                                       save_as_images, display_in_terminal, one_hot_from_int)\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "model = BigGAN.from_pretrained('biggan-deep-128')\n",
    "\n",
    "truncation = 0.5\n",
    "class_vector = one_hot_from_int(323)\n",
    "#class_vector = one_hot_from_names([\"car\"], batch_size=1)\n",
    "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=1, seed = 0)\n",
    "\n",
    "noise_vector = torch.from_numpy(noise_vector)\n",
    "class_vector = torch.from_numpy(class_vector)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "save_as_images(output, \"butterfly_target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/201 [00:00<?, ?it/s]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_0_0.png\n",
      "  1%|          | 2/201 [00:28<42:10, 12.71s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_2_0.png\n",
      "  2%|▏         | 4/201 [01:11<57:44, 17.59s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_4_0.png\n",
      "  3%|▎         | 6/201 [01:43<53:25, 16.44s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_6_0.png\n",
      "  4%|▍         | 8/201 [02:04<42:27, 13.20s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_8_0.png\n",
      "  5%|▍         | 10/201 [02:14<28:26,  8.93s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_10_0.png\n",
      "  6%|▌         | 12/201 [02:23<21:14,  6.74s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_12_0.png\n",
      "  7%|▋         | 14/201 [02:33<18:51,  6.05s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_14_0.png\n",
      "  8%|▊         | 16/201 [03:03<34:13, 11.10s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_16_0.png\n",
      "  9%|▉         | 18/201 [03:47<49:27, 16.22s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_18_0.png\n",
      " 10%|▉         | 20/201 [04:05<37:44, 12.51s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_20_0.png\n",
      " 11%|█         | 22/201 [04:22<31:09, 10.44s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_22_0.png\n",
      " 12%|█▏        | 24/201 [04:53<37:11, 12.61s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_24_0.png\n",
      " 13%|█▎        | 26/201 [05:15<34:17, 11.76s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_26_0.png\n",
      " 14%|█▍        | 28/201 [05:48<40:42, 14.12s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_28_0.png\n",
      " 15%|█▍        | 30/201 [06:06<33:11, 11.65s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_30_0.png\n",
      " 16%|█▌        | 32/201 [06:35<36:23, 12.92s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_32_0.png\n",
      " 17%|█▋        | 34/201 [07:05<37:10, 13.36s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_34_0.png\n",
      " 18%|█▊        | 36/201 [07:19<28:21, 10.31s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_36_0.png\n",
      " 19%|█▉        | 38/201 [07:34<23:41,  8.72s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_38_0.png\n",
      " 20%|█▉        | 40/201 [07:49<21:38,  8.07s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_40_0.png\n",
      " 21%|██        | 42/201 [08:03<19:56,  7.53s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_42_0.png\n",
      " 22%|██▏       | 44/201 [08:18<19:43,  7.54s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_44_0.png\n",
      " 23%|██▎       | 46/201 [08:36<21:07,  8.18s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_46_0.png\n",
      " 24%|██▍       | 48/201 [08:51<19:26,  7.62s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_48_0.png\n",
      " 25%|██▍       | 50/201 [09:06<18:57,  7.53s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_50_0.png\n",
      " 26%|██▌       | 52/201 [09:21<18:32,  7.46s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_52_0.png\n",
      " 27%|██▋       | 54/201 [09:37<19:12,  7.84s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_54_0.png\n",
      " 28%|██▊       | 56/201 [09:52<18:46,  7.77s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_56_0.png\n",
      " 29%|██▉       | 58/201 [10:06<17:37,  7.39s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_58_0.png\n",
      " 30%|██▉       | 60/201 [10:21<17:09,  7.30s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_60_0.png\n",
      " 31%|███       | 62/201 [10:34<16:04,  6.94s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_62_0.png\n",
      " 32%|███▏      | 64/201 [10:48<15:50,  6.94s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_64_0.png\n",
      " 33%|███▎      | 66/201 [11:03<16:28,  7.32s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_66_0.png\n",
      " 34%|███▍      | 68/201 [11:18<16:31,  7.45s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_68_0.png\n",
      " 35%|███▍      | 70/201 [11:32<15:28,  7.09s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_70_0.png\n",
      " 36%|███▌      | 72/201 [11:45<14:55,  6.94s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_72_0.png\n",
      " 37%|███▋      | 74/201 [12:00<14:58,  7.08s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_74_0.png\n",
      " 38%|███▊      | 76/201 [12:15<15:02,  7.22s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_76_0.png\n",
      " 39%|███▉      | 78/201 [12:29<14:32,  7.09s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_78_0.png\n",
      " 40%|███▉      | 80/201 [12:42<13:36,  6.75s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_80_0.png\n",
      " 41%|████      | 82/201 [12:56<13:52,  6.99s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_82_0.png\n",
      " 42%|████▏     | 84/201 [13:11<13:52,  7.12s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_84_0.png\n",
      " 43%|████▎     | 86/201 [13:29<15:47,  8.24s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_86_0.png\n",
      " 44%|████▍     | 88/201 [13:43<14:12,  7.55s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_88_0.png\n",
      " 45%|████▍     | 90/201 [14:03<16:05,  8.70s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_90_0.png\n",
      " 46%|████▌     | 92/201 [14:18<14:44,  8.11s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_92_0.png\n",
      " 47%|████▋     | 94/201 [14:32<13:13,  7.42s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_94_0.png\n",
      " 48%|████▊     | 96/201 [14:45<12:25,  7.10s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_96_0.png\n",
      " 49%|████▉     | 98/201 [15:00<12:26,  7.25s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_98_0.png\n",
      " 50%|████▉     | 100/201 [15:14<12:14,  7.28s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_100_0.png\n",
      " 51%|█████     | 102/201 [15:28<11:46,  7.14s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_102_0.png\n",
      " 52%|█████▏    | 104/201 [15:43<11:41,  7.24s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_104_0.png\n",
      " 53%|█████▎    | 106/201 [16:00<12:52,  8.13s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_106_0.png\n",
      " 54%|█████▎    | 108/201 [16:20<13:51,  8.94s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_108_0.png\n",
      " 55%|█████▍    | 110/201 [16:32<11:04,  7.30s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_110_0.png\n",
      " 56%|█████▌    | 112/201 [16:41<08:40,  5.84s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_112_0.png\n",
      " 57%|█████▋    | 114/201 [16:55<09:44,  6.72s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_114_0.png\n",
      " 58%|█████▊    | 116/201 [17:14<11:14,  7.93s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_116_0.png\n",
      " 59%|█████▊    | 118/201 [17:26<09:45,  7.05s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_118_0.png\n",
      " 60%|█████▉    | 120/201 [17:38<08:32,  6.33s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_120_0.png\n",
      " 61%|██████    | 122/201 [17:48<07:40,  5.83s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_122_0.png\n",
      " 62%|██████▏   | 124/201 [18:00<07:22,  5.75s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_124_0.png\n",
      " 63%|██████▎   | 126/201 [18:11<07:08,  5.71s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_126_0.png\n",
      " 64%|██████▎   | 128/201 [18:30<09:25,  7.75s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_128_0.png\n",
      " 65%|██████▍   | 130/201 [18:50<10:26,  8.82s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_130_0.png\n",
      " 66%|██████▌   | 132/201 [19:09<10:40,  9.29s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_132_0.png\n",
      " 67%|██████▋   | 134/201 [19:25<09:42,  8.69s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_134_0.png\n",
      " 68%|██████▊   | 136/201 [19:41<08:50,  8.16s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_136_0.png\n",
      " 69%|██████▊   | 138/201 [19:51<07:01,  6.69s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_138_0.png\n",
      " 70%|██████▉   | 140/201 [20:03<06:22,  6.26s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_140_0.png\n",
      " 71%|███████   | 142/201 [20:13<05:19,  5.41s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_142_0.png\n",
      " 72%|███████▏  | 144/201 [20:22<04:42,  4.95s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_144_0.png\n",
      " 73%|███████▎  | 146/201 [20:33<04:56,  5.40s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_146_0.png\n",
      " 74%|███████▎  | 148/201 [20:44<04:48,  5.45s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_148_0.png\n",
      " 75%|███████▍  | 150/201 [20:55<04:36,  5.41s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_150_0.png\n",
      " 76%|███████▌  | 152/201 [21:07<04:34,  5.60s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_152_0.png\n",
      " 77%|███████▋  | 154/201 [21:16<04:04,  5.20s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_154_0.png\n",
      " 78%|███████▊  | 156/201 [21:31<04:54,  6.54s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_156_0.png\n",
      " 79%|███████▊  | 158/201 [21:39<03:41,  5.14s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_158_0.png\n",
      " 80%|███████▉  | 160/201 [21:47<03:02,  4.45s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_160_0.png\n",
      " 81%|████████  | 162/201 [21:55<02:44,  4.22s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_162_0.png\n",
      " 82%|████████▏ | 164/201 [22:02<02:27,  3.99s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_164_0.png\n",
      " 83%|████████▎ | 166/201 [22:10<02:16,  3.89s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_166_0.png\n",
      " 84%|████████▎ | 168/201 [22:17<02:06,  3.84s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_168_0.png\n",
      " 85%|████████▍ | 170/201 [22:25<01:57,  3.79s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_170_0.png\n",
      " 86%|████████▌ | 172/201 [22:32<01:48,  3.75s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_172_0.png\n",
      " 87%|████████▋ | 174/201 [22:40<01:41,  3.75s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_174_0.png\n",
      " 88%|████████▊ | 176/201 [22:47<01:34,  3.77s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_176_0.png\n",
      " 89%|████████▊ | 178/201 [22:55<01:25,  3.73s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_178_0.png\n",
      " 90%|████████▉ | 180/201 [23:02<01:18,  3.74s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_180_0.png\n",
      " 91%|█████████ | 182/201 [23:10<01:10,  3.72s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_182_0.png\n",
      " 92%|█████████▏| 184/201 [23:17<01:03,  3.74s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_184_0.png\n",
      " 93%|█████████▎| 186/201 [23:25<00:56,  3.77s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_186_0.png\n",
      " 94%|█████████▎| 188/201 [23:32<00:49,  3.77s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_188_0.png\n",
      " 95%|█████████▍| 190/201 [23:40<00:41,  3.75s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_190_0.png\n",
      " 96%|█████████▌| 192/201 [23:47<00:33,  3.73s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_192_0.png\n",
      " 97%|█████████▋| 194/201 [23:55<00:26,  3.76s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_194_0.png\n",
      " 98%|█████████▊| 196/201 [24:03<00:19,  3.83s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_196_0.png\n",
      " 99%|█████████▊| 198/201 [24:10<00:11,  3.80s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_198_0.png\n",
      "100%|█████████▉| 200/201 [24:18<00:03,  3.78s/it]INFO:pytorch_pretrained_biggan.utils:Saving image to butterfly_200_0.png\n",
      "100%|██████████| 201/201 [24:21<00:00,  7.27s/it]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import squeezenet1_0\n",
    "from tqdm import trange\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.eval().to(DEVICE)\n",
    "\n",
    "\n",
    "semantic_model = squeezenet1_0(pretrained=True).to(DEVICE)\n",
    "semantic_model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Flatten()\n",
    "    )\n",
    "semantic_model = semantic_model.eval()\n",
    "\n",
    "trunction = 0.5\n",
    "\n",
    "class_vector = one_hot_from_int(323)\n",
    "#class_vector = one_hot_from_names(['car'], batch_size=1)\n",
    "class_vector = torch.from_numpy(class_vector)\n",
    "\n",
    "noise = truncated_noise_sample(truncation=truncation, batch_size=1, seed=99)\n",
    "noise = torch.nn.Parameter(torch.tensor(noise, requires_grad=True).float().to(DEVICE))\n",
    "noise_optim = torch.optim.Adam([noise], lr=0.05)\n",
    "\n",
    "\n",
    "\n",
    "L = []\n",
    "L_pixel = []\n",
    "L_semantic = []\n",
    "\n",
    "for iteration in trange(0, 201):\n",
    "    noise_optim.zero_grad()\n",
    "\n",
    "    y_hat = model(noise, class_vector, truncation)\n",
    "\n",
    "    semantic_loss = ((semantic_model(y_hat) - semantic_model(output)) ** 2).mean() ** .5 #-cos_sim(semantic_model(y_hat), semantic_model(output))\n",
    "    L_semantic.append(semantic_loss.item())\n",
    "\n",
    "    pixel_loss = abs(y_hat - output).mean()\n",
    "    L_pixel.append(pixel_loss.item())\n",
    "\n",
    "    loss = semantic_loss + 30 * pixel_loss\n",
    "    L.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    noise_optim.step()\n",
    "\n",
    "    if iteration % 2 == 0:\n",
    "        save_as_images(y_hat, f\"butterfly_{iteration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(L)\n",
    "plt.plot([x*30 for x in L_pixel], 'r')\n",
    "plt.plot(L_semantic, 'b')\n",
    "\n",
    "plt.show()"
   ]
  }
 ]
}