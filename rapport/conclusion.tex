\chapter{Conclusion et Perspectives}
Pour la première étape nous avons réussis à générer des images grâce à pix2pix nous avons eu 3 modèles différents (uniquement avec les voitures, toutes les images de la dataset PASCAL avec et sans le background), Nous avons obtenu des résultats pas très satisfaisant ou les images générées sont presque carrément différentes. Ensuite pour la deuxième étape nous avons expérimenté le BigGan  pré entrainé avec la dataset imageNet ou nous avons changé un peu  l'algorithme en modifiant l'espace Latent pour la première phase de cette expérimentation nous avons changé que le bruit  ensuit dans la deuxième phase nous avons réussis à changer le vecteur de classe et le bruit afin de comparer les résultats. Nous avons remarqué que la génération d'image après avoir modifié que le bruit en choisissant des classes de qui se ressemble juste un peu, notre algorithme permet de générer des images similaire (ex. chat vers chien) par contre quand nous choisissant deux classes qui sont complètement différentes notre algorithme génère une image complétement dissimilaire à notre image but.

La similarité est vraiment un monde vaste, nous avons réussis à obtenir des résultats qui sont assez satisfaisants, mais il existe d'autres approches. Afin d'améliorer les résultats il faudrait essayer de générer plusieurs exemple en modifiant l'espace latent (bruit, classe, bruit et classe) et cela en changeant l'optimiseur et en changeant aussi les poids des loss sémantique et pixels.  A la fin une comparaison devra être faite par des sujets humains sur les images pour choisir les meilleurs poids et le meilleur optimiseur et bien évidement le choix du changement de l'espace latent.